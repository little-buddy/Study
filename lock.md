# Java 并发引发的锁问题
## 基础知识
硬件催生了多并发编程的发展。通过并发编程的形式可以将多核CPU的计算能力发挥到极致，性能得到提升。

### 并发编程的优缺点
- 为什么要用到并发

        适合并发的场景：
        图像处理领域，一张1024X768像素的图片，所有像素都遍历一遍需要很长的时间，而面对这样的计算可以充分利用多核的计算能力
        比如网上购物，将 减库存、生成订单等等这些操作拆分利用多线程技术来完成
- 并发编程的优缺点
        
        优势
        充分利用多核CPU计算能力、方便业务进行拆分，提升应用性能
        缺点
        频繁的上下文切换：时间片是CPU分配给各个线程的时间，因为时间非常短，所以CPU通过不断切换线程，让我觉得多个线程是同时执行的，时间片一般是几十毫秒。需要保存当前的状态以便后续可以恢复。切换时是非常损耗性能。
          优化方式：
           - 无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，减少上下文切换时间
           - CAS算法：利用Atomic下使用CAS算法来更新数据，使用了乐观锁，可以有效的减少一部分不必要的锁竞争带来的上下文切换
           - 使用最少的线程：避免创建不必要的线程
           - 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换
        线程安全问题
         线程安全的定义跟纯函数的定义很像，就是需要保证任意一次执行结构都一致，也就意味着只要存在死锁的可能它就是线程不安全的
         - 死锁 线程A需要B的资源的时候又因为B需要获得A所占用的资源才能得到释放，导致他们互相等待
         避免死锁的方式：
          - 避免一个线程同时获得多个锁
          - 避免一个线程在锁内部占有多个资源，尽量保证每个锁只占用一个资源
          - 尝试使用定时锁，使用lock.tryLock(timeOut) ,当超时等待时当前线程不会阻塞。感觉就是超时报异常释放资源
          - 对于数据库锁，加锁和解锁必须在一个数据连接里，否则会出现解锁失败的情况
        Problem ：如何保证线程安全、如何正确理解由于JMM内存模型在原子性、有序性、可见性带来的问题，比如数据脏读，DCL等问题


- 易混淆的概念
```
同步：方法调用一开始，调用者必须等待被调用的方法结束后，调用者后面的代码才能执行
异步：调用者不用管被调用方法是否完成都会继续执行后面的代码
```
```
并发：指的是多个任务交替进行
并行：指真正意义上的同时进行。实际上只有一个CPU是无法并行的

你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。
你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。  （不一定是同时的）
你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。
```
[本例子摘自 山鬼谣弋痕夕 的CSDN 博客](https://blog.csdn.net/weixin_30363263/article/details/80732156?utm_source=copy)

```
阻塞：比如一个资源占有了临界区资源，那么其他线程需要这个资源就必须进行等待该资源的释放，会导致等待的线程挂起，这种情况就是阻塞
非阻塞：在调用某个方法返回之前会继续执行下面的程序，但它会每隔一段时间去询问前面调用的那个方法是否有返回，如果有返回执行返回对应的方法
非阻塞式 JS 的写法还是很好懂的
```

```
临界区：用来表示一种公共资源或者说是共享数据的，当它被某个线程占有，其余想要使用该资源都必须等待占有资源的线程释放才能执行
```
  
### 线程的状态和基本操作
- 如何新建线程
- 线程状态的转换 
- 线程的基本操作
- 守护线程Daemon
## 并发理论
- JMM内存结构

出现线程安全一般是因为主内存和工作内存数据不一致性和重排序导致的，而解决线程安全的问题最重要的就是理解这两种问题是怎么来的，转而理解它的核心在于理解java内存模型JMM

在多线程条件下，多个线程肯定会相互协作完成一件事情，一般来说就会涉及到多个线程间相互通信告知彼此的状态以及当前的执行结果。为了性能优化还会涉及到编译器指令重排序和处理器指令重排序。

在并发编程中主要需要解决两个问题：1、线程之间如何通信；2、线程之间如何完成同步。通信是指线程之间以何种机制来交换信息，主要有2种：共享内存和消息传递。java内存模型是贡献内存的并发模型，线程之间主要通过读-写共享变量来完成隐式通信。 -内存可见性问题-

哪些是共享变量<br>
在java程序中所有实例域、静态域和数组元素都是放在堆内存中(所有线程均可访问到，是可以共享的)，而局部变量、方法定义参数和异常处理器参数不会再程序间共享。共享数据会出现线程安全问题，而非共享数据不会出现线程安全的问题

CPU的处理速度和主存的读写速度不是一个量级的，为了平衡这种巨大的差距，每个CPU都会有缓存。因此，共享变量会先放在主存中，每个线程都有属于自己的工作内存，并且会把位于主存中的共享变量拷贝到自己的工作内存，之后的读写操作均位于工作内存的变量副本，并在某个时刻将工作内存的变量副本写会到主存中。JMM就是实现这个模型的名称，并且它可以决定一个线程对共享变量的写入何时对其他线程是可见的。

线程A和线程B要完成通信的话要经历如下两步：
1、线程A从主存中将共享变量读入线程A的工作内存后并进行操作，之后将数据重新写回到主存中；2、线程B从主存中读取最新的共享变量
如果线程A更新后数据没有及时写回主存，而此时线程B读到的是过去的数据，就出现个了 脏读 现象，可以通过同步机制(控制不同线程间操作发生的相对顺序)或通过volatile关键字使得变量强制刷新到主存，从而对每个线程都是可见的
- 重排序 
在不改变程序执行结果的前提下，尽可能提高并行度。JMM对底层尽量减少约束，使其能够发挥自身优势。因此，在执行程序时，为了提高性能，编译器和处理器常常会对指令进行重排序

源代码 -> 编译器优化重排序 -> 指令级并行重排序 -> 内存系统重排序 -> 最终执行的指令序列

1、编译器优化的重排序。在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序
2、指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不能存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序
3、内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行

`as-if-serial`
计算机并不是按我们的代码顺序进行执行的，但最终给人的感觉确是按顺序执行的


- happens-before规则

为了不让程序员去了解底层而又能高效进行开发。指定了六条规则

JMM 通过happens-before 关系向程序员提供跨线程的内存可见性保证(如果线程A的写操作与B线程的读操作之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作对b操作可见)

可见性定义：
```
1、如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而第一个操作的执行顺序排在第二个操作之前
2、两个操作之间存在happens-before关系，并不意味着java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法
```
上面的1 是 JMM对程序员的承诺。如果A happens-before B，那么java内存模型将向程序员保证--A操作的结果将对B可见，且A的执行顺序排在B之前

上面的2 是 JMM对编译器和处理器重排序的约束规则。只要不改变程序的执行结果，编译器和处理器怎么优化都行。这样做的原因是程序员并不关心是否被重排序，而是关心程序执行时的语义不能被改变。

as-if-serial是相对于单线程而言的，happens-before是相对于多线程而言的

- 程序顺序规则：一个线程的每个操作，happens-before于该线程中的任意后续操作
- 监视器锁规则：对于一个锁的解锁，happens-before与随后这个锁的加锁
- volatile变量规则：对于一个volatile域的写，happens-before于任意后续对这个volatile域的读
- 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C
- join规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B的任意操作happens-before与线程A从ThreadB.join操作成功返回
- 程序中断规则：对线程interrupted() 方法的调用先于被中断线程的代码检测到中断时间的发生
- 对象finalize规则：一个对象的初始化完成，先于发生它的finalize方法的开始

## 并发关键字
### 让你彻底了解 Synchronized
`synchronized`修饰
```
方法
实例方法 -> 锁住的是该类的实例对象
public synchronized void method
静态方法 -> 类对象
public static synchronized void method
代码块
实例对象 -> 该类的实例对象
synchronized(this)
class对象 -> 类对象
synchronized(Synchronized.class)
任意实例对象Object -> 配置的实例对象
synchronized(arg)
```

线程获取锁是一个悲观锁策略
CAS(compare and swap)(无锁操作)是一种乐观锁

乐观锁假设所有线程访问共享资源的时候不会发生冲突，不会发生冲突自然不会阻塞线程。无锁操作是比较交换来鉴别线程是否冲突，出现冲突就尝试当前操作直到没有冲突为止

意味着获取值失败的时候会重新尝试获取

java SE 1.6中，锁一共有4种状态，级别从高到低依次是：无状态锁、偏向锁状态、轻量级锁状态和重量级锁状态

```
偏向锁 -> 存在大多数时候，一个锁可能被一个线程持有很少发生竞争，那当这个线程第一次获取到锁的时候，会记录下这个偏向线程ID，以后每次同步会比较锁的偏向ID和当前线程ID是否一致，如果一致则直接进入同步，退出也是。就不需要加锁和解锁都去更新CAS对象头。如果不一致说明发生了竞争，那么这个时候锁就需要膨胀为轻量级锁

轻量锁
1、轻量级锁每次退出同步快都需要释放锁，而偏向锁是在竞争发生才释放锁
2、每次进入退出同步块都需要CAS更新对象头
3、争夺轻量级锁失败时，自旋尝试抢占锁

轻量级所适合在竞争情况下使用，自旋锁可以保证响应速度快，但自旋操作会占用CPU，所以一些计算时间长的操作不适合使用轻量级锁

当轻量锁出现竞争就需要膨胀为重量级锁，而重量锁适合 同步块执行时间长的情况
```
- 如何使用 synchronized
- monitor机制 
- synchronized的happens-before关系
- synchronized的内存语义
- 锁优化
- 锁升级策略
### 彻底了解volatile
- 实现原理
- happens-before的关系推导
- 内存语义
- 内存语义的实现
### 你真的了解final吗？
- 如何使用
- final的重排序规则
- final实现原理
- final引用不能从构造函数中溢出(this逃逸)
### 三大性质总结 原子性、有序性、可见性
- 原子性：synchronized
- 可见性：synchronized，volatile
- 有序性：synchronized，volatile
## lock体系
### 初始lock与AbstractQueuedSynchronizer(AQS)
- Lock 和 synchronized 比较
- AQS设计意图
- 如何使用AQS实现自定义同步组件
- 可重写方法
- AQS提供的模板方法
### 深入理解 AbstractQueuedSychronizer
- AQS 同步队列的数据结构
- 独占式锁
- 共享式锁
### 再一次理解 Reentrantlock
- 重入锁的实现原理
- 公平锁的实现原理
- 非公平锁的实现原理
- 公平所和非公平锁的比较
### 深入理解读写锁ReentrantReadWriteLock
- 如何表示读写状态
- Writelock的获取和释放
- ReadLock的获取和释放
- 锁降级策略
- 生成 condition等待队列
- 应用场景
### 详解Condition的await和signal等待/通知机制
- 与Object的wait/notify机制相比具有的特性
- 与Object的wait/notify相对应的方法
- 底层数据结构
- await 实现原理
- signal/signalAll 实现原理
- await 和 signal/signalAll的结合使用
### LockSupport工具
- 主要功能
- 与synchronized阻塞唤醒相比具有的特色
## 并发容器 不是java开发，这一章还是比较难懂的
### 并发容器之ConcurrentHashMap
- 关键属性
- 重要内部类
- 涉及到的CAS操作
- 构造方法
- put执行流程
- get执行流程
- 扩容机制
- 用于统计size的方法的执行流程
- 1.8 的ConcurrentHashMap与之前版本的比较
### 并发容器之CopyOnWriteArrayList
- 实现原理
- COW 和 ReentrantReadWriteLock的区别
- 应用场景
- 为什么具有弱一致性
- COW的缺点
### 并发容器之ConcurrentLinkedQueue
- 实现原理
- 数据结构
- 核心方法
- HOPS延迟更新的设计意图
### 并发容器之ThreadLocal
- 实现原理
- set方法原理
- get方法原理
- remove方法原理
- ThreadLocalMap
### ThreadLocal内存泄漏问题
- ThreadLocal内存泄漏原理
- ThreadLocal的最佳实践
- 应用场景
### 并发容器之BlockingQueue
- BlockingQueue的基本操作
- 常用的BlockingQueue
## 线程池 Executor体系
### 线程池实现原理
- 为什么要用到线程池
- 执行流程
- 构造各个参数的意义
- 如何关闭线程池
- 如何配置线程池
### 线程池之ScheduledThreadPoolExecutor
- 类结构
- 常用方法
- ScheduledFutureTask
- DelayedWorkQueue
### FutureTask基本操作总结
- FutureTask的集中状态
- get方法
- cancel方法
- 应用场景
- 实现Runable接口

### 原子类操作、并发工具、并发实践 就很JAVA了，对于前端的我来说有点远了

# 次 MD 是对java并发的一次整理，原帖出自 https://github.com/CL0610/Java-concurrency




### 再一次
## 一致性、事务
### 事务ACID特性
### 事务的隔离级别
### MVCC
## 锁
AQS(abstract queue synchronizer)
### Java 中的锁和同步类
### 公平锁 & 非公平锁
### 悲观锁
### 乐观锁 & CAS
### ABA 问题
### CopyOnWrite容器
### RingBuffer
### 可重入锁 & 不可重入锁
### 互斥锁 & 共享锁
### 死锁